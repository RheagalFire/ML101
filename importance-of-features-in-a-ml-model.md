# Importance of Features in a ML model

A model can predict based on a set of vectors what your outcome would be but sometimes that is not the objective. So what if your objective is to study the features that affect the outcome rather than build a predictive model. This Objective can be achieved by using a game theory approach that involves fairly distributing both gains and costs to actors working in coalition. 

This article [here](https://towardsdatascience.com/shap-explain-any-machine-learning-model-in-python-24207127cad7) talks in length about it 

There is a library called shap for which helps you visualize individual contributions of features towards an output. 

![](<.gitbook/assets/image (25).png>)

**Here is the official **[**Link**](https://github.com/slundberg/shap)**, check out their GIT Repo.**
